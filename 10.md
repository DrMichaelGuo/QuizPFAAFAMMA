
### Chapter 10: Web Scraping and Accessing Cryptocurrency Data - Multiple Choice Questions

**Choose the correct answer. Only one option is correct. Answers are listed at the end.**

### 1. What is the primary purpose of a `robots.txt` file on a website?
- A. To speed up webpage loading time  
- B. To provide a sitemap for human visitors  
- C. To control which parts of a site are accessible to automated tools  
- D. To manage user passwords and authentication  

### 2. Which Python library is used to parse HTML content for web scraping?
- A. pandas  
- B. numpy  
- C. BeautifulSoup  
- D. matplotlib  

### 3. Which HTTP status code indicates that access to a resource is forbidden?
- A. 200  
- B. 403  
- C. 404  
- D. 500  

### 4. In ethical scraping, what is the purpose of adding a delay using `time.sleep()`?
- A. To hide the scraping activity  
- B. To convert HTML to JSON  
- C. To avoid overloading the target server  
- D. To compress downloaded files  

### 5. What does the following `robots.txt` directive mean?  

```
User-agent: *
Disallow:
```

- A. Only some user-agents are allowed  
- B. All automated tools are blocked from accessing the site  
- C. No restrictions; scraping is allowed everywhere  
- D. Only human users can access the site  

### 6. What type of data should NOT be scraped without a lawful basis under UK GDPR?
- A. Public domain company logos  
- B. Personal names and email addresses  
- C. Product prices  
- D. Industry classifications  

### 7. What is the purpose of the `User-Agent` header in a scraping request?
- A. To compress HTML content  
- B. To identify the scraping script to the server  
- C. To display output in a DataFrame  
- D. To download files automatically  

### 8. What does the function `parse_number()` in this chapter do?
- A. Generates random integers  
- B. Adds commas and brackets to numbers  
- C. Converts string values to numeric types, handling brackets and commas  
- D. Extracts hyperlinks from HTML  

### 9. Which Python library is used to create a ZIP archive of downloaded files?
- A. os  
- B. requests  
- C. shutil  
- D. zipfile  

### 10. What should a responsible scraping log include?
- A. The programming language used  
- B. The browser version used  
- C. The date, time, target URL, and number of records scraped  
- D. The number of cookies stored

### 11. Which API is used in this chapter to retrieve Bitcoin and Ethereum prices?
- A. Binance API  
- B. Google Finance API  
- C. CoinGecko API  
- D. Polygon API

### 12. Which library is used to send HTTP requests to the CoinGecko API?
- A. urllib  
- B. selenium  
- C. requests  
- D. http.client  

---

### **Answer Key**
1. C  
2. C  
3. B  
4. C  
5. C  
6. B  
7. B  
8. C  
9. C  
10. C
11. C
12. C
